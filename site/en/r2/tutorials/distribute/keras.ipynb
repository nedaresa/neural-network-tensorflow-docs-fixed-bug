{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tuOe1ymfHZPu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "cell_type": "markdown",
      "source": [
        "# Distributed Training in TensorFlow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r6P32iYYV27b"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/distribution_strategy_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/distribute/distribution_strategy_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/distribute/distribution_strategy_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "The `tf.distribute.Strategy` API provides an abstraction for distributing your training\n",
        "across multiple processing units. Our goal is to allow users to use existing\n",
        "models and training code with minimal changes to enable distributed training.\n",
        "\n",
        "This tutorial uses the `tf.distribute.MirroredStrategy`, which\n",
        "does in-graph replication with synchronous training on many GPUs on one machine.\n",
        "Essentially, it copies all of the model's variables to each processor.\n",
        "Then, it uses [all-reduce](link to explanation) to combine the gradients from all processors and applies the combined value to all copies of the model.\n",
        "\n",
        "`MirroredStategy` is the only distribution strategy currently available in TensorFlow core. Advanced users can implement the `tf.distribute.Strategy` API to create custom strategies. Additional strategies are planned for TensorFlow core, and will be included in the future. \n",
        "For more details, see the [Distribution Strategy README](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MUXex9ctTuDB"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras API\n",
        "\n",
        "To keep this example as clear as possible, we'll use the `tf.keras` API to build the model and training loop. (For an advanced example using a custom training loop, see [this tutorial](/tutorials/distribute/training_loops))."
      ]
    },
    {
      "metadata": {
        "id": "Dney9v7BsJij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r8S3ublR7Ay8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "74rHkS_DB3X2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "!pip install tf-nightly-gpu-2.0-preview \n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hXhefksNKk2I"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OtnnUwvmB3X5"
      },
      "cell_type": "markdown",
      "source": [
        "We're using the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset for this example, so start by loading it from [TensorFlow Datasets](https://www.tensorflow.org/datasets). This returns a dataset in `tf.data` format."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iXMJ3G9NB3X6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lHAPqG8MtS8M"
      },
      "cell_type": "markdown",
      "source": [
        "Setting `with_info` to `True` includes the metadata for the entire dataset, which is being saved here to `ds_info`.\n",
        "Among other things, this metadata object includes the number of train and test examples.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p1xWxKcnhar9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_train_examples = ds_info.splits['train'].num_examples\n",
        "num_test_examples = ds_info.splits['test'].num_examples\n",
        "# You can also get ds_info.splits.total_num_examples\n",
        "\n",
        "BUFFER_SIZE = num_train_examples\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0Wm5rsL2KoDF"
      },
      "cell_type": "markdown",
      "source": [
        "## Input data pipeline\n",
        "\n",
        "Pixel values, which are 0-255, [have to be normalized to the 0-1 range](https://en.wikipedia.org/wiki/Feature_scaling). Put this normalization in a function, so it can be called on each example."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Eo9a46ZeJCkm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gRZu2maChwdT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GrjVhv-eKuHD"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Distribution Strategy"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TlH8vx6BB3X9"
      },
      "cell_type": "markdown",
      "source": [
        "To distribute a Keras model on multiple GPUs using `MirroredStrategy`, first instantiate a `MirroredStrategy` object."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4j0tdf4YB3X9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cY3KA_h2iVfN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4xsComp8Kz5H"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1BnQYQTpB3YA"
      },
      "cell_type": "markdown",
      "source": [
        "Create and compile the Keras model in the context of `strategy.scope`."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IexhL_vIB3YA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  # TODO(yashkatariya): Add accuracy when b/122371345 is fixed.\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam())\n",
        "                #metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8i6OU5W9Vy2u"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the callbacks.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YOXO5nvvK3US"
      },
      "cell_type": "markdown",
      "source": [
        "The callbacks used here are:\n",
        "\n",
        "*   *Tensorboard*: This callback writes a log for Tensorboard which allows you to visualize the graphs.\n",
        "*   *Model Checkpoint*: This callback saves the model after every epoch.\n",
        "*   *Learning Rate Scheduler*: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
        "\n",
        "For illustrative purposes, we're also adding a print callback to display the Learning Rate in the notebook."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A9bwLCcXzSgy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wpU-BEdzJDbK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jKhiMgXtKq2w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print ('\\nLearning rate for epoch {} is {}'.format(epoch + 1, \n",
        "                                                       model.optimizer.lr.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YVqAbR6YyNQh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, \n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "70HXgDQmK46q"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6EophnOAB3YD"
      },
      "cell_type": "markdown",
      "source": [
        "Now, train the model in the usual way, calling `fit` on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7MVw_6CqB3YD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=10, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NUcWAUUupIvG"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see below, the checkpoints are getting saved."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JQ4zeSTxKEhB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the checkpoint directory\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qor53h7FpMke"
      },
      "cell_type": "markdown",
      "source": [
        "To see how the model perform, load the latest checkpoint and call `evaluate` on the test data.\n",
        "\n",
        "Call `evaluate` as before using appropriate datasets."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JtEwxiTgpQoP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss = model.evaluate(eval_dataset)\n",
        "print ('Eval loss: {}'.format(eval_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IIeF2RWfYu4N"
      },
      "cell_type": "markdown",
      "source": [
        "To see the output, you can download and view the TensorBoard logs at the terminal.\n",
        "\n",
        "```\n",
        "$ tensorboard --logdir=path/to/log-directory\n",
        "```"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LnyscOkvKKBR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -sh ./logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8uNqWRdDMl5S"
      },
      "cell_type": "markdown",
      "source": [
        "## What's next?\n",
        "\n",
        "Read the [distribution strategy guide](../../../guide/distribute_strategy.ipynb).\n",
        "\n",
        "Try the [Distributed Training with Custom Training Loops](training_loops.ipynb) tutorial.\n",
        "\n",
        "----\n",
        "\n",
        "`tf.distribute.Strategy` is actively under development and we will be adding more examples and tutorials in the near future. Please give it a try. We welcome your feedback via [issues on GitHub](https://github.com/tensorflow/tensorflow/issues/new)."
      ]
    }
  ]
}