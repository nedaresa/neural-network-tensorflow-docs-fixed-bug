{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_rewrite.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "DolcuS5N_rtH"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RwuVZLpO_fRF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jvzYBfWU_tLz"
      },
      "cell_type": "markdown",
      "source": [
        "# Load text with tf.data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JyPrxUD7_wd2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "MAX_LEN = 256\n",
        "NUM_REVIEWS = 25000\n",
        "\n",
        "UNKNOWN_WORD = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1ZUgEqDPAE8r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the training data\n",
        "train_raw = tfds.load(name='imdb_reviews/plain_text', split=tfds.Split.TRAIN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qqLRCH2NTjXd"
      },
      "cell_type": "markdown",
      "source": [
        "The model will not take review texts as input directly. \n",
        "\n",
        "Instead, the input will be a tensor with a \"slot\" for each unique word that occurs at least once in any review (about 90,000 unique words in the entire dataset). If a word appears in a review, the slot representing that word has a `1` value. Otherwise, the slot has a `0`. (This representation is called a [bag of words](https://developers.google.com/machine-learning/glossary/#bag_of_words)).\n",
        "\n",
        "The first step to making this conversion is to map each unique word in the training data to an integer (its \"slot\" number in the input tensors).\n",
        "\n",
        "Create a function to *tokenize* a single text entry.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AVtcqlY4BBtj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "  # Replace line breaks with spaces.\n",
        "  example['text'] = tf.strings.regex_replace(example['text'], r'\\<br \\/\\>', ' ')\n",
        "  # Replace non-word characters with spaces.\n",
        "  example['text'] = tf.strings.regex_replace(example['text'], r'[\\W\\d]+', ' ')\n",
        "  # Split string into an array of words\n",
        "  example['text'] = tf.strings.split([example['text']], sep=' ').values\n",
        "  return example\n",
        "\n",
        "def get_vocabulary(dataset):\n",
        "  dataset = dataset.map(tokenize)\n",
        "  dataset = dataset.flat_map(lambda example: tf.data.Dataset.\n",
        "                             from_tensor_slices(example['text']))\n",
        "  dataset = dataset.apply(tf.data.experimental.unique())\n",
        "  dataset = tf.data.Dataset.zip((dataset, tf.data.experimental.Counter(1)))\n",
        "\n",
        "  vocabulary = {}\n",
        "  for word, index in iter(dataset):\n",
        "    vocabulary[word.numpy()] = index\n",
        "  return vocabulary\n",
        "\n",
        "vocabulary = get_vocabulary(train_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "21XtQvOpBNGh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XXTQ21eTB7O_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_indexed_dataset(vocabulary, dataset):\n",
        "\n",
        "  def index_and_pad(example):\n",
        "\n",
        "    def helper(words):\n",
        "      result = []\n",
        "      for word, _ in zip(words, range(MAX_LEN)):\n",
        "        if word in vocabulary:\n",
        "          result.append(vocabulary[word])\n",
        "        else:\n",
        "          result.append(UNKNOWN_WORD)\n",
        "      return tf.pad(result, [[0, MAX_LEN - len(result)]], 'CONSTANT')\n",
        "\n",
        "    example['text'] = tf.numpy_function(helper, [example['text']], tf.int64)\n",
        "    return example\n",
        "\n",
        "  dataset = dataset.map(tokenize)\n",
        "  dataset = dataset.map(index_and_pad)\n",
        "  dataset = dataset.shuffle(10 * BATCH_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.map(lambda example: (example['text'], example['label']))\n",
        "  return dataset\n",
        "\n",
        "train_data = get_indexed_dataset(vocabulary, train_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Icy-b9Iz32N6",
        "outputId": "5b2bc29d-8804-480e-cbfb-67c849d8d832",
        "colab": {
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "def get_model(input_dim, embedding_dim=50, hidden_units=[100]):\n",
        "  \"\"\"Create a Keras Sequential model with layers.\n",
        "\n",
        "  Args:\n",
        "    input_dim: (int) Input dimensions for input layer.\n",
        "    embedding_dim: (int) Embedding dimension for embedding layer.\n",
        "    hidden_units: [int] the layer sizes of the DNN (input layer first)\n",
        "\n",
        "  Returns:\n",
        "    A Keras model.\n",
        "  \"\"\"\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(input_dim=input_dim,\n",
        "                                      output_dim=embedding_dim,\n",
        "                                      input_length=MAX_LEN))\n",
        "  model.add(tf.keras.layers.GlobalMaxPool1D())\n",
        "  for units in hidden_units:\n",
        "    model.add(tf.keras.layers.Dense(units, activation=tf.keras.backend.relu))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "model = get_model(len(vocabulary) + 1)\n",
        "model.fit(train_data, epochs=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49/49 [==============================] - 17s 344ms/step - loss: 0.6815 - accuracy: 0.6916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google3.third_party.tensorflow.python.keras.callbacks.History at 0x7fbb154779d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YyD_XyVC4E2y",
        "outputId": "52cd727c-7b20-47de-f960-83c6ae5153df",
        "colab": {
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "test_raw = tfds.load(name='imdb_reviews/plain_text', split=tfds.Split.TEST)\n",
        "test_data = get_indexed_dataset(vocabulary, test_raw)\n",
        "model.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     49/Unknown - 24s 498ms/step - loss: 0.6518 - accuracy: 0.7999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.65184134001634564, 0.79992002]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5Kuw4iEw6oXJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}