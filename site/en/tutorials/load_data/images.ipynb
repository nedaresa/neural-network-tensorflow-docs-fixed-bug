{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loading Images.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ucMoYase6URl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load images with `tf.data`"
      ]
    },
    {
      "metadata": {
        "id": "_Wwu5SXZmEkB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/images\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hoQQiZDB6URn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "illI4c426URn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start by [installing TensorFlow](https://www.tensorflow.org/install/).\n",
        "\n",
        "And testing the installation:"
      ]
    },
    {
      "metadata": {
        "id": "DHz3JONNEHlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "tf.VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wO0InzL66URu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Retrieve the images\n",
        "\n",
        "Before you start any training, you'll need a set of images to teach the network about the new classes you want to recognize. We've created an archive of creative-commons licensed flower photos to use initially. "
      ]
    },
    {
      "metadata": {
        "id": "rN-Pc6Zd6awg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_root = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)\n",
        "data_root = pathlib.Path(data_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFkFK74oO--g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After downloading 218MB, you should now have a copy of the flower photos available in your working directory."
      ]
    },
    {
      "metadata": {
        "id": "7onR_lWE7Njj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for item in data_root.iterdir():\n",
        "  print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkM-IpB-6URx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inspect the images\n",
        "Now let's have a quick look at a couple of the images, so we know what we're dealing with:"
      ]
    },
    {
      "metadata": {
        "id": "wNGateQJ6UR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attributions = (data_root/\"LICENSE.txt\").read_text().splitlines()[4:]\n",
        "attributions = [line.split(' CC-BY') for line in attributions]\n",
        "attributions = dict(attributions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgowG2xu88Io",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import IPython.display as display\n",
        "\n",
        "def show_image(image_path):\n",
        "    display.display(display.Image(str(image_path)))\n",
        "    \n",
        "    image_rel = pathlib.Path(image_path).relative_to(data_root)\n",
        "    caption = \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\n",
        "    display.display(display.HTML(\"<div>%s</div>\" % caption))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIjLi-nX0txI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "all_image_paths = list(data_root.glob('*/*'))\n",
        "random.shuffle(all_image_paths)\n",
        "\n",
        "show_image(random.choice(all_image_paths))\n",
        "show_image(random.choice(all_image_paths))\n",
        "show_image(random.choice(all_image_paths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OaNOr-co3WKk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Determine the label for each image"
      ]
    },
    {
      "metadata": {
        "id": "-weOQpDw2Jnu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "List the available labels:"
      ]
    },
    {
      "metadata": {
        "id": "ssUZ7Qh96UR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "label_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9l_JEBql2OzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assign an index to each label:"
      ]
    },
    {
      "metadata": {
        "id": "Y8pCV46CzPlp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "label_to_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkXsHg162T9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a list of every file, and its label index"
      ]
    },
    {
      "metadata": {
        "id": "q62i1RBP4Q02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_image_labels = [label_to_index[path.parent.name] for path in all_image_paths]\n",
        "all_image_labels[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6H9Z5Mq63nSH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A basic `tf.data.Dataset`"
      ]
    },
    {
      "metadata": {
        "id": "GN-s04s-6Luq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The easiest way to build a `tf.data.Dataset` is using the `from_tensor_slices` method.\n",
        "\n",
        "Slicing the array of strings, results in a dataset of strings:"
      ]
    },
    {
      "metadata": {
        "id": "6oRPG3Jz3ie_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "string_paths = [str(path) for path in all_image_paths]\n",
        "\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(string_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uML4JeMmIAvO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `output_shapes` and `output_types` fields describe the content of each item in the dataset. In this case it is a set of scalar binary-strings"
      ]
    },
    {
      "metadata": {
        "id": "mIsNflFbIK34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('shape: ', repr(path_ds.output_shapes))\n",
        "print('type: ', path_ds.output_types)\n",
        "print()\n",
        "print(path_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6FNqPbxkbdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A dataset of `(image, label)` pairs"
      ]
    },
    {
      "metadata": {
        "id": "YgvrWLKG67-x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Slicing both the paths and labels together gives a dataset of `(path, label)` pairs."
      ]
    },
    {
      "metadata": {
        "id": "AgBsAiV06udj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_ds = tf.data.Dataset.from_tensor_slices((string_paths, all_image_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBgixEXHLpND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for path,cls in path_ds.take(3):\n",
        "  print(path.numpy(), \" : \", label_names[cls.numpy()])\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yA2F09SJLMuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `shapes` and `types`, are now tuples of shapes and types as well, describing each field:"
      ]
    },
    {
      "metadata": {
        "id": "DuVYNinrLL-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('shape: ', path_ds.output_shapes)\n",
        "print('type: ', path_ds.output_types)\n",
        "print()\n",
        "print(path_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5L09icm9iph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load and format the images"
      ]
    },
    {
      "metadata": {
        "id": "SbqqRUS79ooq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a simple function to load, decode and format the image data."
      ]
    },
    {
      "metadata": {
        "id": "HmUiZJNU73vA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def format_image(path):\n",
        "  image = tf.read_file(path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize_images(image, [192, 192])\n",
        "  image = (image/128.0) - 1\n",
        "\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DP7X54sEIYgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image_label(path,label):\n",
        "  image = tf.read_file(path)\n",
        "  image = format_image(image)\n",
        "\n",
        "  label = tf.cast(label, dtype=tf.int64)\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ratpWRt9x_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use the `map` method to convert the dataset of `(path,label)` pairs to `(image,label)` pairs.\n",
        "\n",
        "Like all dataset methods, `map` does not execute the transformation immediately. It only executes as needed."
      ]
    },
    {
      "metadata": {
        "id": "6K1AnLq_7k4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# many threads will be waiting on disk reads.\n",
        "image_ds = path_ds.map(process_image_label, num_parallel_calls=16)\n",
        "image_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OcxMQxBT9MQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for image,label in image_ds.take(3):\n",
        "  plt.figure()\n",
        "  plt.imshow((image+1)/2)\n",
        "  plt.title(label_names[label])\n",
        "  plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vYGCgJuR_9Qp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pipe to a model for training"
      ]
    },
    {
      "metadata": {
        "id": "wwZavzgsIytz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To train a model with this dataset you will want the data:\n",
        "\n",
        "* To be well shuffeled.\n",
        "* To be batched.\n",
        "* To repeat forever.\n",
        "* Batches to available immediately when needed.\n",
        "\n",
        "These features can be easily added using the `tf.data` api."
      ]
    },
    {
      "metadata": {
        "id": "uZmZJx8ePw_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "# Shuffling the paths takes less memory than shuffling the images.\n",
        "# Setting a buffer size larger than the dataset ensures that the data is completely shuffled.\n",
        "ds = path_ds.shuffle(buffer_size=10000) \n",
        "ds = ds.map(process_image_label, num_parallel_calls=16)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(1).repeat()\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RBVw3AtGQmWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Quick Transfer learning with `keras.Applications`"
      ]
    },
    {
      "metadata": {
        "id": "GBBZMSuAmQVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Grab a copy of mobilenet v2 from `tf.keras.applications` and set it to be non-trainable:"
      ]
    },
    {
      "metadata": {
        "id": "KbJrXn9omO_g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mobile_net = tf.keras.applications.MobileNetV2(input_shape=[192, 192, 3], include_top=False)\n",
        "mobile_net.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CboYya6LmdQI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Drop that into a `tf.keras.Sequential` model.\n",
        "\n",
        "The mobilenet returns a `6x6` spatial grid of features for each image. So use `GlobalAveragePooling2D` to average over those space dimensions, before the output `Dense` layer:"
      ]
    },
    {
      "metadata": {
        "id": "X0ooIU9fNjPJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  mobile_net,\n",
        "  # This mobilnet returns a 6x6 feature map, take the spatial average.\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(len(label_names))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pFc4I_J2nNOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compile the model to describe the training procedure:"
      ]
    },
    {
      "metadata": {
        "id": "ZWGqLEWYRNvv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kug5Wg66UJjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjtWzr3_UM0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(model.trainable_variables) # Dense `weights` and `bias`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_glpYZ-nYC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start the model training:"
      ]
    },
    {
      "metadata": {
        "id": "AnXPRNWoTypI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(ds, epochs=1, steps_per_epoch=3)  # steps_per_epoch=math.ceil(len(all_image_paths)/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMVnoBcG_NlQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Performance\n",
        "The simple pipeline used above reads each file individually, on each epoch. This is fine for local training on CPU but may not be sufficient for GPU training, and is totally inapprpriate for any sort of distributed training. \n",
        "\n",
        "Streaming files sequentially can be much more efficient."
      ]
    },
    {
      "metadata": {
        "id": "oNmQqgGhLWie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To investigate, first build a simple function to check the performance of our datasets:"
      ]
    },
    {
      "metadata": {
        "id": "_gFVe1rp_MYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def timeit(ds, batches=100):\n",
        "  overall_start = time.time()\n",
        "  # Fetch a single batch to prime the pipeline (fill the shuffle buffer),\n",
        "  # before starting the timer\n",
        "  it = iter(ds.take(batches+1))\n",
        "  next(it)\n",
        "\n",
        "  start = time.time()\n",
        "  for i,(images,labels) in enumerate(it):\n",
        "    if i%10 == 0:\n",
        "      print('.',end='')\n",
        "  print()\n",
        "  end = time.time()\n",
        "\n",
        "  duration = end-start\n",
        "  print(\"100 batches: {} s\".format(duration))\n",
        "  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*batches/duration))\n",
        "  print(\"Total time: {}s\".format(end-overall_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYiOr4vdLcNX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The performance of out current dataset is:"
      ]
    },
    {
      "metadata": {
        "id": "Su_P8s8ZA41P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsLlXMO7EWBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cache"
      ]
    },
    {
      "metadata": {
        "id": "lV1NOn2zE2lR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use `tf.data.Dataset.cache` to easily take advantage of the performance boost of working with in memory data.\n",
        "\n",
        "Here the images are cached, after being pre-precessed (decoded and resized):"
      ]
    },
    {
      "metadata": {
        "id": "qj_U09xpDvOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = path_ds.map(process_image_label, num_parallel_calls=16)\n",
        "ds = ds.cache()\n",
        "ds = ds.shuffle(buffer_size=10000) \n",
        "ds = ds.batch(BATCH_SIZE).prefetch(1).repeat()\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdxpvQ7VEo3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKX6ergKb_xd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUzpG4lYNkN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the data doesn't fit in memory, use a cache file. \n",
        "\n",
        "The cache file also has the advantage that it can be-"
      ]
    },
    {
      "metadata": {
        "id": "vIvF8K4GMq0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = path_ds.map(process_image_label, num_parallel_calls=16)\n",
        "ds = ds.cache(filename='./cache.tf-data')\n",
        "ds = ds.shuffle(buffer_size=10000)\n",
        "ds = ds.batch(BATCH_SIZE).prefetch(1).repeat()\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eTIj6IOmM4yA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZhVdR8MbaUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqOVlf8tFrDU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TFRecord File"
      ]
    },
    {
      "metadata": {
        "id": "y1llOTwWFzmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TFRecord files are a simple format to store a sequence of binary blobs. In this case, it gives most of the performance boost of using the `.cache` method."
      ]
    },
    {
      "metadata": {
        "id": "EqtARqKuHQLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images_ds = tf.data.Dataset.from_tensor_slices(string_paths).map(tf.read_file)\n",
        "tfrec = tf.contrib.data.TFRecordWriter('images.tfrec')\n",
        "tfrec.write(images_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9PVUL2SFufn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images_ds = tf.data.TFRecordDataset('images.tfrec').map(format_image, num_parallel_calls=16)\n",
        "labels_ds = tf.data.Dataset.from_tensor_slices(all_image_labels)\n",
        "\n",
        "ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
        "ds = ds.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(1)\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ReSapoPK22E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeit(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fm-QR_7wOsnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}