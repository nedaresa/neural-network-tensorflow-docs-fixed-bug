{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCQY7jpBfMur"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "z6X9omPnfO_h"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QQJJyDzqGRb"
   },
   "source": [
    "# Eager Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1xdylywqUSX"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/eager\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/eager.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGjDcGxIqEfX"
   },
   "source": [
    "Tensorflowのeager executionは、グラフを作成する必要なしに、即座に評価します。\n",
    "コードを実行すると、グラフを構築する代わりに具体的な値を返します。\n",
    "この記述方法により、TensorFlowおよびデバッグモデルを使い始めるのが簡単になり、さらにコードの記述量も削減されます。\n",
    "このガイドの内容を実行するためには、対話的インタプリタ`python`を起動し、以下のコードサンプルを実行してください。\n",
    "\n",
    "TensorFlow's eager execution is an imperative programming environment that\n",
    "evaluates operations immediately, without building graphs: operations return\n",
    "concrete values instead of constructing a computational graph to run later. This\n",
    "makes it easy to get started with TensorFlow and debug models, and it\n",
    "reduces boilerplate as well. To follow along with this guide, run the code\n",
    "samples below in an interactive `python` interpreter.\n",
    "\n",
    "Eager Executionは研究や実験のための柔軟な機械学習基盤であり、以下を提供します。\n",
    "\n",
    "Eager Execution is a flexible machine learning platform for research and\n",
    "experimentation, providing:\n",
    "\n",
    "* *直感的なインタフェース*-記述したコードを自然に構造化してPythonのデータ構造を使います。スモールなモデルとデータですばやく実験を繰り返すことができます。\n",
    "* *Easier debugging*-opsを直接呼び出すことで、実行中のモデルやテストをチェック変更をテストすることができます。Python標準のデバッグツールを用いて即座にエラーのレポーティングができます。\n",
    "* *自然な制御フロー*-グラフ制御フローの代わりにPythonの制御フローを利用し、動的なモデルのパラメータ変更をシンプルにします。\n",
    "\n",
    "* *An intuitive interface*—Structure your code naturally and use Python data\n",
    "  structures. Quickly iterate on small models and small data.\n",
    "* *Easier debugging*—Call ops directly to inspect running models and test\n",
    "  changes. Use standard Python debugging tools for immediate error reporting.\n",
    "* *Natural control flow*—Use Python control flow instead of graph control\n",
    "  flow, simplifying the specification of dynamic models.\n",
    "  \n",
    "Eager ExecutionはTensorflowのほとんどのoperationとGPUアクセラレーションをサポートします。\n",
    "Eager Executionの実行例については、以下を参照してください。\n",
    "[tensorflow/contrib/eager/python/examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples).\n",
    "\n",
    "Eager execution supports most TensorFlow operations and GPU acceleration. For a eager execution\n",
    "collection of examples running in eager execution, see:\n",
    "[tensorflow/contrib/eager/python/examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples).\n",
    "\n",
    "Note: いくつかのモデルはEager Executionを有効化することでオーバヘッドが増える可能性があります。\n",
    "パフォーマンスは向上し続けていますが、もしも問題を発見したら、バグ報告してベンチマークを共有してください。\n",
    "\n",
    "Note: Some models may experience increased overhead with eager execution\n",
    "enabled. Performance improvements are ongoing, but please\n",
    "[file a bug](https://github.com/tensorflow/tensorflow/issues) if you find a\n",
    "problem and share your benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBAeIwOMrYk8"
   },
   "source": [
    "## セットアップと基本的な使い方\n",
    "## Setup and basic usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48P3-8q4qEfe"
   },
   "source": [
    "Eager Executionをはじめるためには、プログラムやコンソールセッションの最初に、`tf.enable_eager_execution()`を追加してください。\n",
    "プログラムが呼び出す他のモジュールにこの操作を追加しないでください。\n",
    "\n",
    "To start eager execution, add `tf.enable_eager_execution()` to the beginning of\n",
    "the program or console session. Do not add this operation to other modules that\n",
    "the program calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "7aFsD8csqEff"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_G1zZT5qEfh"
   },
   "source": [
    "これでTensorFlowのオペレーションを実行することができ、結果はすぐに返ります。\n",
    "\n",
    "Now you can run TensorFlow operations and the results will return immediately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hien2IEqwLQ"
   },
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "9gsI54pbqEfj"
   },
   "outputs": [],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(\"hello, {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajFn6qsdqEfl"
   },
   "source": [
    "Eager Executionを有効化することで、Tensorflowの操作は変わります。-Tensorflowは即時に評価して結果をPythonに返すようになります。\n",
    "`tf.Tensor` オブジェクトは計算グラフのノードへのシンボリックハンドルの代わりに具体的な値を参照します。\n",
    "セッションを構築して実行するための計算グラフがないため、`print（）`やデバッガを使って容易に結果を調べることができます。\n",
    "勾配計算を終了することなくテンソル値を評価、出力、およびチェックすることができます。\n",
    "\n",
    "Enabling eager execution changes how TensorFlow operations behave—now they\n",
    "immediately evaluate and return their values to Python. `tf.Tensor` objects\n",
    "reference concrete values instead of symbolic handles to nodes in a computational\n",
    "graph. Since there isn't a computational graph to build and run later in a\n",
    "session, it's easy to inspect results using `print()` or a debugger. Evaluating,\n",
    "printing, and checking tensor values does not break the flow for computing\n",
    "gradients.\n",
    "\n",
    "Eager Executionは[NumPy](http://www.numpy.org/)を利用しています。NumPyのオペレーションは`tf.Tensor`を引数として受け取ることができます。\n",
    "TensorFlow [math operations](https://www.tensorflow.org/api_guides/python/math_ops) はPythonオブジェクトとNumpy arrayを`tf.Tensor`にコンバートします。\n",
    "`tf.Tensor.numpy`メソッドはオブジェクトの値をNumPyの`ndarray`形式で返します。\n",
    "\n",
    "Eager execution works nicely with [NumPy](http://www.numpy.org/). NumPy\n",
    "operations accept `tf.Tensor` arguments. TensorFlow \n",
    "[math operations](https://www.tensorflow.org/api_guides/python/math_ops) convert\n",
    "Python objects and NumPy arrays to `tf.Tensor` objects. The\n",
    "`tf.Tensor.numpy` method returns the object's value as a NumPy `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTO0_5TYqz1n"
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dp14YT8Gq4r1"
   },
   "outputs": [],
   "source": [
    "# ブロードキャストのサポート\n",
    "# Broadcasting support\n",
    "b = tf.add(a, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69p3waMfq8cQ"
   },
   "outputs": [],
   "source": [
    "# オペレータのオーバーロードがサポートされています\n",
    "# Operator overloading is supported\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ui025t1qqEfm"
   },
   "outputs": [],
   "source": [
    "# NumPy valueの使用\n",
    "# Use NumPy values\n",
    "import numpy as np\n",
    "\n",
    "c = np.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq_aFRzWrCua"
   },
   "outputs": [],
   "source": [
    "# Tensorからnumpyの値を得る\n",
    "# Obtain numpy value from a tensor:\n",
    "print(a.numpy())\n",
    "# => [[1 2]\n",
    "#     [3 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jdg3nZFwqEfp"
   },
   "source": [
    "`tf.contrib.eager` モジュールは、Eager ExecutionとGraph Executionの両方の環境で利用可能なシンボルが含まれており、[Graph Execution](#work_with_graphs)方式での記述においても利用できます:\n",
    "\n",
    "The `tf.contrib.eager` module contains symbols available to both eager and graph execution\n",
    "environments and is useful for writing code to [work with graphs](#work_with_graphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "N-2lSGiHqEfq"
   },
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H08f9ss9qEft"
   },
   "source": [
    "## 動的な制御フロー\n",
    "## Dynamic control flow\n",
    "\n",
    "Eager Executionの主要なメリットは、モデルを実行する際にホスト言語のすべての機能性が利用できることです。\n",
    "\n",
    "A major benefit of eager execution is that all the functionality of the host\n",
    "language is available while your model is executing. So, for example,\n",
    "it is easy to write [fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "0fudRMeUqEfu"
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "  counter = tf.constant(0)\n",
    "  max_num = tf.convert_to_tensor(max_num)\n",
    "  for num in range(1, max_num.numpy()+1):\n",
    "    num = tf.constant(num)\n",
    "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "      print('FizzBuzz')\n",
    "    elif int(num % 3) == 0:\n",
    "      print('Fizz')\n",
    "    elif int(num % 5) == 0:\n",
    "      print('Buzz')\n",
    "    else:\n",
    "      print(num.numpy())\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2cKknQWrJLB"
   },
   "outputs": [],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kA-aC3BqEfy"
   },
   "source": [
    "この関数はテンソル値に依存する条件式を持ち、実行時にこれらの値を表示します。\n",
    "\n",
    "This has conditionals that depend on tensor values and it prints these values\n",
    "at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zn3mp-j6rjnk"
   },
   "source": [
    "## モデルの構築\n",
    "\n",
    "## Build a model\n",
    "\n",
    "多くの機械学習モデルはレイヤーを積み重ねよって表されます。Eager ExecutionでTensorFlowを使うときは、自分でレイヤーの内容を記述するか、もしくは `tf.keras.layers`パッケージで提供されるレイヤーを使うことができます。\n",
    "\n",
    "Many machine learning models are represented by composing layers. When\n",
    "using TensorFlow with eager execution you can either write your own layers or\n",
    "use a layer provided in the `tf.keras.layers` package.\n",
    "\n",
    "レイヤーを表すために任意のPythonオブジェクトを使用できますが、\n",
    "TensorFlowには便利な基本クラスとして `tf.keras.layers.Layer`があります。独自のレイヤーを実装するためには、\n",
    "このクラスを継承したクラスを作成します。\n",
    "\n",
    "While you can use any Python object to represent a layer,\n",
    "TensorFlow has `tf.keras.layers.Layer` as a convenient base class. Inherit from\n",
    "it to implement your own layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "kvXiJsmyqEfz"
   },
   "outputs": [],
   "source": [
    "class MySimpleLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, output_units):\n",
    "    super(MySimpleLayer, self).__init__()\n",
    "    self.output_units = output_units\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # The build method gets called the first time your layer is used.\n",
    "    # Creating variables on build() allows you to make their shape depend\n",
    "    # on the input shape and hence removes the need for the user to specify\n",
    "    # full shapes. It is possible to create variables during __init__() if\n",
    "    # you already know their full shapes.\n",
    "    self.kernel = self.add_variable(\n",
    "      \"kernel\", [input_shape[-1], self.output_units])\n",
    "\n",
    "  def call(self, input):\n",
    "    # Override call() instead of __call__ so we can perform some bookkeeping.\n",
    "    return tf.matmul(input, self.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eo3qgrVCqEf2"
   },
   "source": [
    " `MySimpleLayer`の代わりに、その機能のスーパーセットを持っている（バイアスを加えることもできる）、`tf.keras.layers.Dense`レイヤーを使用してください。\n",
    "\n",
    "Use `tf.keras.layers.Dense` layer instead  of `MySimpleLayer` above as it has\n",
    "a superset of its functionality (it can also add a bias).\n",
    "\n",
    "レイヤをモデルに組み立てるとき、レイヤの線形スタックである\n",
    "モデルを表すために `tf.keras.Sequential`を使うことができます。この書き方は基本的なモデルを扱いやすいです。\n",
    "\n",
    "When composing layers into models you can use `tf.keras.Sequential` to represent\n",
    "models which are a linear stack of layers. It is easy to use for basic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "VrfLnhNPqEf3"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=(784,)),  # must declare input shape\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dms3mduTqEf6"
   },
   "source": [
    "もしくは、 `tf.keras.Model`を継承してモデルをクラスにまとめます。 \n",
    "これはレイヤ自身であるレイヤのコンテナで、 `tf.keras.Model`オブジェクトが他の` tf.keras.Model`オブジェクトを含むことを可能にします。\n",
    "\n",
    "Alternatively, organize models in classes by inheriting from `tf.keras.Model`.\n",
    "This is a container for layers that is a layer itself, allowing `tf.keras.Model`\n",
    "objects to contain other `tf.keras.Model` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "MwWxQmNOqEf7"
   },
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(MNISTModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(units=10)\n",
    "    self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "  def call(self, input):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    result = self.dense1(input)\n",
    "    result = self.dense2(result)\n",
    "    result = self.dense2(result)  # reuse variables from dense2 layer\n",
    "    return result\n",
    "\n",
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a639YaF4qEf-"
   },
   "source": [
    "入力データのshape（各次元のサイズ）は最初のレイヤに初めて入力データを渡すときにセットされるため、\n",
    "モデル構築時に`tf.keras.Model`クラスに入力データのshape（各次元のサイズ）を設定する必要はありません。\n",
    "\n",
    "\n",
    "It's not required to set an input shape for the `tf.keras.Model` class since\n",
    "the parameters are set the first time input is passed to the layer.\n",
    "\n",
    "`tf.keras.layers`クラスは独自のモデル変数を作成し、包含します。このモデル変数は、レイヤーオブジェクトがメモリから削除されるときに一緒に削除されます。レイヤー変数を共有するには、それらのオブジェクトを共有します。\n",
    "\n",
    "`tf.keras.layers` classes create and contain their own model variables that\n",
    "are tied to the lifetime of their layer objects. To share layer variables, share\n",
    "their objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8huKpuuAwICq"
   },
   "source": [
    "## Eager training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mp2lCCZYrxHd"
   },
   "source": [
    "### 勾配の計算\n",
    "\n",
    "### Computing gradients\n",
    "\n",
    "[自動微分](https://en.wikipedia.org/wiki/Automatic_differentiation)はニューラルネットワークの学習で利用される[バックプロパゲーション](https://en.wikipedia.org/wiki/Backpropagation)などの機械学習アルゴリズムの実装を行う上で便利です。\n",
    "Eager Executionでは、勾配計算をあとで行うためのトレースオペレーションのために`tf.GradientTape` を利用します。\n",
    "\n",
    "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
    "is useful for implementing machine learning algorithms such as\n",
    "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation) for training\n",
    "neural networks. During eager execution, use `tf.GradientTape` to trace\n",
    "operations for computing gradients later.\n",
    "\n",
    "`tf.GradientTape` はトレースしない場合に最大のパフォーマンスを提供するオプトイン機能です。異なるオペレーションは各呼び出し中に異なる操作が発生する可能性があるため、すべてのforward-passオペレーションは一つの「テープ」に記録されます。勾配を計算するには、テープを逆方向に再生してから破棄します。特定の `tf.GradientTape`は一つのグラデーションしか計算できません。後続の呼び出しは実行時エラーをスローします。\n",
    "\n",
    "`tf.GradientTape` is an opt-in feature to provide maximal performance when\n",
    "not tracing. Since different operations can occur during each call, all\n",
    "forward-pass operations get recorded to a \"tape\". To compute the gradient, play\n",
    "the tape backwards and then discard. A particular `tf.GradientTape` can only\n",
    "compute one gradient; subsequent calls throw a runtime error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "7g1yWiSXqEf-"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = w * w\n",
    "\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkHs32GqweYS"
   },
   "source": [
    "### モデル学習\n",
    "\n",
    "### Train a model\n",
    "\n",
    "以下のexampleはMNISTという手書き数字分類を行うマルチレイヤーモデルを作成します。\n",
    "Eager Execution環境における学習可能なグラフを構築するためのオプティマイザーとレイヤーAPIを提示します。\n",
    "\n",
    "The following example creates a multi-layer model that classifies the standard\n",
    "MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build\n",
    "trainable graphs in an eager execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38kymXZowhhz"
   },
   "outputs": [],
   "source": [
    "# mnistデータのを取得し、フォーマットする\n",
    "\n",
    "# Fetch and format the mnist data\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl1K8rOowmwT"
   },
   "outputs": [],
   "source": [
    "# モデルを作成する\n",
    "\n",
    "# Build the model\n",
    "mnist_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvyk-HgGwxwl"
   },
   "source": [
    "学習を行わずとも、モデルを呼び出して、Eager Executionにより、出力を検査することができます。\n",
    "\n",
    "Even without training, call the model and inspect the output in eager execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsxystjBwxLS"
   },
   "outputs": [],
   "source": [
    "for images,labels in dataset.take(1):\n",
    "  print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3PGa8G7qEgB"
   },
   "source": [
    "kerasモデルは組み込みで学習のループを回すメソッド`fit`がありますが、よりカスタマイズが必要な場合もあるでしょう。 Eager Executionを用いて実装された学習ループのサンプルを以下に示します。\n",
    "\n",
    "While keras models have a builtin training loop (using the `fit` method), sometimes you need more customization. Here's an example, of a training loop implemented with eager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzRhM7JDnaEG"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "0m1xAXrmqEgJ"
   },
   "outputs": [],
   "source": [
    "for (batch, (images, labels)) in enumerate(dataset.take(400)):\n",
    "  if batch % 10 == 0:\n",
    "    print('.', end='')\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = mnist_model(images, training=True)\n",
    "    loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "  loss_history.append(loss_value.numpy())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables),\n",
    "                            global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vG5ql_2vYB5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKpOlHPLqEgl"
   },
   "source": [
    "### 値とオプティマイザ\n",
    "\n",
    "### Variables and optimizers\n",
    "\n",
    "`tf.Variable` オブジェクトは、学習中にアクセスされるミュータブルな`tf.Tensor`値を格納し、自動微分を容易にします。\n",
    "モデルのパラメータは、変数としてクラスにカプセル化できます。\n",
    "\n",
    "`tf.Variable` objects store mutable `tf.Tensor` values accessed during\n",
    "training to make automatic differentiation easier. The parameters of a model can\n",
    "be encapsulated in classes as variables.\n",
    "\n",
    "`tf.GradientTape`と共に` tf.Variable`を使うことでモデルパラメータはよりカプセル化されます。例えば、上の\n",
    "の自動微分の例は以下のように書き換えることができます：\n",
    "\n",
    "Better encapsulate model parameters by using `tf.Variable` with\n",
    "`tf.GradientTape`. For example, the automatic differentiation example above\n",
    "can be rewritten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "nnQLBYmEqEgm"
   },
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "    self.W = tf.Variable(5., name='weight')\n",
    "    self.B = tf.Variable(10., name='bias')\n",
    "  def call(self, inputs):\n",
    "    return inputs * self.W + self.B\n",
    "\n",
    "# 3 ＊ ２ + 2を近似するトイデータセット\n",
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "  error = model(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, [model.W, model.B])\n",
    "\n",
    "# 定義：\n",
    "# 1. モデル\n",
    "# 2. モデルパラメータに関する損失関数の導関数\n",
    "# 3. 導関数に基づいて変数を更新するストラテジ。\n",
    "\n",
    "# Define:\n",
    "# 1. A model.\n",
    "# 2. Derivatives of a loss function with respect to model parameters.\n",
    "# 3. A strategy for updating the variables based on the derivatives.\n",
    "model = Model()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "# 学習ループ\n",
    "# Training loop\n",
    "for i in range(300):\n",
    "  grads = grad(model, training_inputs, training_outputs)\n",
    "  optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n",
    "                            global_step=tf.train.get_or_create_global_step())\n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPjb8nRWqEgr"
   },
   "source": [
    "## Eager Executionの途中でオブジェクトのステータスを使用する\n",
    "\n",
    "## Use objects for state during eager execution\n",
    "\n",
    "Graph Executionでは、プログラムの状態（変数など）はglobal collectionに格納され、それらの存続期間は `tf.Session`オブジェクトによって管理されます。\n",
    "対照的に、Eager Executionの間、状態オブジェクトの存続期間は、対応するPythonオブジェクトの存続期間によって決定されます。\n",
    "\n",
    "With graph execution, program state (such as the variables) is stored in global\n",
    "collections and their lifetime is managed by the `tf.Session` object. In\n",
    "contrast, during eager execution the lifetime of state objects is determined by\n",
    "the lifetime of their corresponding Python object.\n",
    "\n",
    "### 変数とオブジェクト\n",
    "\n",
    "### Variables are objects\n",
    "\n",
    "Eager Executionの間、変数はオブジェクトへの最後の参照が削除され、その後削除されるまで存続します。\n",
    "\n",
    "During eager execution, variables persist until the last reference to the object\n",
    "is removed, and is then deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "A2boS674qEgs"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  with tf.device(\"gpu:0\"):\n",
    "    v = tf.Variable(tf.random_normal([1000, 1000]))\n",
    "    v = None  # v no longer takes up GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scMjg6L6qEgv"
   },
   "source": [
    "### オブジェクトベースの保存\n",
    "\n",
    "### Object-based saving\n",
    "\n",
    "`tf.train.Checkpoint`はチェックポイントを用いて`tf.Variable`を保存および復元することができます：\n",
    "\n",
    "`tf.train.Checkpoint` can save and restore `tf.Variable`s to and from\n",
    "checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7z5xRfdHzZOQ"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10.)\n",
    "checkpoint = tf.train.Checkpoint(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IffrUVG7zyVb"
   },
   "outputs": [],
   "source": [
    "x.assign(2.)   # 変数に新しい値を割り当てて保存する # Assign a new value to the variables and save.\n",
    "checkpoint_path = './ckpt/'\n",
    "checkpoint.save('./ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "eMT9koCoqEgw"
   },
   "outputs": [],
   "source": [
    "x.assign(11.)  # 保存後に変数の値を変更する # Change the variable after saving.\n",
    "\n",
    "# チェックポイントから値を復元する\n",
    "\n",
    "# Restore values from the checkpoint\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "print(x)  # => 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbFnP-yLqEgx"
   },
   "source": [
    "モデルを保存して読み込むために、 `tf.train.Checkpoint`は隠れ変数なしにオブジェクトの内部状態を保存します。 `モデル`、 `オプティマイザ`、そしてグローバルステップの状態を記録するには、それらを `tf.train.Checkpoint`に渡します。\n",
    "\n",
    "To save and load models, `tf.train.Checkpoint` stores the internal state of objects,\n",
    "without requiring hidden variables. To record the state of a `model`,\n",
    "an `optimizer`, and a global step, pass them to a `tf.train.Checkpoint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "hWZHyAXMqEg0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "checkpoint_dir = tempfile.mkdtemp()\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "root = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                           model=model,\n",
    "                           optimizer_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "root.save(checkpoint_prefix)\n",
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yoD0VJ7qEg3"
   },
   "source": [
    "### オブジェクト指向メトリクス\n",
    "\n",
    "### Object-oriented metrics\n",
    "\n",
    "`tfe.metrics`はオブジェクトとして保存されます。新しいデータを呼び出し可能オブジェクトに渡してメトリクスを更新し、 `tfe.metrics.result`メソッドを使って結果を取得します。次に例を示します:\n",
    "\n",
    "`tfe.metrics` are stored as objects. Update a metric by passing the new data to\n",
    "the callable, and retrieve the result using the `tfe.metrics.result` method,\n",
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "9ccu0iAaqEg5"
   },
   "outputs": [],
   "source": [
    "m = tfe.metrics.Mean(\"loss\")\n",
    "m(0)\n",
    "m(5)\n",
    "m.result()  # => 2.5\n",
    "m([8, 9])\n",
    "m.result()  # => 5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BE8cXErYqEg8"
   },
   "source": [
    "#### サマリとTensorBoard\n",
    "\n",
    "#### Summaries and TensorBoard\n",
    "\n",
    "TensorBoardはモデルの学習プロセスを理解、デバッグ、最適化するための可視化ツールです。プログラムの実行中に書き込まれる\n",
    "サマリイベントを使用します。\n",
    "\n",
    "[TensorBoard](../guide/summaries_and_tensorboard.md) is a visualization tool for\n",
    "understanding, debugging and optimizing the model training process. It uses\n",
    "summary events that are written while executing the program.\n",
    "\n",
    "`tf.contrib.summary`はEager ExecutionとGraph Executionの両方の環境と互換性があります。 \n",
    "`tf.contrib.summary.scalar`のようなサマリオペレーションはモデル構築の間に挿入されます。\n",
    "例えば、100のグローバルステップごとにサマリを記録するには、次のようにします。\n",
    "\n",
    "`tf.contrib.summary` is compatible with both eager and graph execution\n",
    "environments. Summary operations, such as `tf.contrib.summary.scalar`, are\n",
    "inserted during model construction. For example, to record summaries once every\n",
    "100 global steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "3PXAJB1GqEg9"
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "logdir = \"./tb/\"\n",
    "writer = tf.contrib.summary.create_file_writer(logdir)\n",
    "writer.set_as_default()\n",
    "\n",
    "for _ in range(10):\n",
    "  global_step.assign_add(1)\n",
    "  # Must include a record_summaries method\n",
    "  with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
    "    # your model code goes here\n",
    "    tf.contrib.summary.scalar('global_step', global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TJSs_wG8Spg"
   },
   "outputs": [],
   "source": [
    "!ls tb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEL4yJe5qEhD"
   },
   "source": [
    "## 高度な自動分類トピック\n",
    "\n",
    "## Advanced automatic differentiation topics\n",
    "\n",
    "### 動的なモデル\n",
    "\n",
    "### Dynamic models\n",
    "\n",
    "`tf.GradientTape`は動的モデルでも使うことができます。 \n",
    "以下の[バックトラックライン検索]（https://wikipedia.org/wiki/Backtracking_line_search）\n",
    "アルゴリズムの例は、複雑な制御フローにも関わらず\n",
    "勾配があり、微分可能であることを除いて、通常のNumPyコードのように見えます。\n",
    "\n",
    "`tf.GradientTape` can also be used in dynamic models. This example for a\n",
    "[backtracking line search](https://wikipedia.org/wiki/Backtracking_line_search)\n",
    "algorithm looks like normal NumPy code, except there are gradients and is\n",
    "differentiable, despite the complex control flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "L518n5dkqEhE"
   },
   "outputs": [],
   "source": [
    "def line_search_step(fn, init_x, rate=1.0):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # Variables are automatically recorded, but manually watch a tensor\n",
    "    tape.watch(init_x)\n",
    "    value = fn(init_x)\n",
    "  grad = tape.gradient(value, init_x)\n",
    "  grad_norm = tf.reduce_sum(grad * grad)\n",
    "  init_value = value\n",
    "  while value > init_value - rate * grad_norm:\n",
    "    x = init_x - rate * grad\n",
    "    value = fn(x)\n",
    "    rate /= 2.0\n",
    "  return x, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03owpCFrqEhH"
   },
   "source": [
    "### 勾配計算のための追加機能\n",
    "\n",
    "### Additional functions to compute gradients\n",
    "\n",
    "`tf.GradientTape`は強力な勾配計算インタフェースですが、\n",
    "自動微分に利用できる別の[Autograd]（https://github.com/HIPS/autograd） スタイルのAPIもあります。\n",
    "これらの関数はテンソルと勾配関数のみを使って、`tf.variables`を使わずに数式コードを書く場合に便利です：\n",
    "\n",
    "`tf.GradientTape` is a powerful interface for computing gradients, but there\n",
    "is another [Autograd](https://github.com/HIPS/autograd)-style API available for\n",
    "automatic differentiation. These functions are useful if writing math code with\n",
    "only tensors and gradient functions, and without `tf.variables`:\n",
    "\n",
    "* `tfe.gradients_function` - 引数をとり、入力関数パラメータの導関数を計算する関数を返します。 \n",
    "入力パラメータはスカラ値を返さなければなりません。返された関数が\n",
    "されると、 `tf.Tensor`オブジェクトのリストを返します：入力関数のそれぞれの\n",
    "引数に対して一つの要素。重要なものすべてを関数パラメータとして渡さなければならないので、\n",
    "多くのtrainableパラメータに依存している場合、これは扱いにくくなります。\n",
    "`tfe.value_and_gradients_function` - ` tfe.gradients_function`に似ていますが、返された関数が呼び出されると、その引数に関する入力関数の\n",
    "導関数のリストに加えて、入力関数からの値を返します。\n",
    "\n",
    "* `tfe.gradients_function` —Returns a function that computes the derivatives\n",
    "  of its input function parameter with respect to its arguments. The input\n",
    "  function parameter must return a scalar value. When the returned function is\n",
    "  invoked, it returns a list of `tf.Tensor` objects: one element for each\n",
    "  argument of the input function. Since anything of interest must be passed as a\n",
    "  function parameter, this becomes unwieldy if there's a dependency on many\n",
    "  trainable parameters.\n",
    "* `tfe.value_and_gradients_function` —Similar to\n",
    "  `tfe.gradients_function`, but when the returned function is invoked, it\n",
    "  returns the value from the input function in addition to the list of\n",
    "  derivatives of the input function with respect to its arguments.\n",
    "\n",
    "次の例では、 `tfe.gradients_function`は引数として` square` 関数を取り、その入力に関して `square`の偏微分\n",
    "導関数を計算する関数を返します。 `3`における` square`の微分を計算するために、 `grad（3.0）`は `6`を返します。\n",
    "\n",
    "In the following example, `tfe.gradients_function` takes the `square`\n",
    "function as an argument and returns a function that computes the partial\n",
    "derivatives of `square` with respect to its inputs. To calculate the derivative\n",
    "of `square` at `3`, `grad(3.0)` returns `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDPFUG-68i-B"
   },
   "outputs": [],
   "source": [
    "def square(x):\n",
    "  return tf.multiply(x, x)\n",
    "\n",
    "grad = tfe.gradients_function(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ow9LHre8k_3"
   },
   "outputs": [],
   "source": [
    "square(3.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rg5ea0kC8nEQ"
   },
   "outputs": [],
   "source": [
    "grad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41D1LzcG87p8"
   },
   "outputs": [],
   "source": [
    "# 平方の二次導関数：\n",
    "\n",
    "# The second-order derivative of square:\n",
    "gradgrad = tfe.gradients_function(lambda x: grad(x)[0])\n",
    "gradgrad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "DotEGcx5qEhH"
   },
   "outputs": [],
   "source": [
    "# 3次導関数はNonenになります：\n",
    "\n",
    "# The third-order derivative is None:\n",
    "gradgradgrad = tfe.gradients_function(lambda x: gradgrad(x)[0])\n",
    "gradgradgrad(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DRAews99F4-"
   },
   "outputs": [],
   "source": [
    "# フロー制御：\n",
    "\n",
    "# With flow control:\n",
    "def abs(x):\n",
    "  return x if x > 0. else -x\n",
    "\n",
    "grad = tfe.gradients_function(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA1jmu_9gyB"
   },
   "outputs": [],
   "source": [
    "grad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zs8JpKw9kir"
   },
   "outputs": [],
   "source": [
    "grad(-3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gieGOf_DqEhK"
   },
   "source": [
    "### カスタム勾配\n",
    "\n",
    "### Custom gradients\n",
    "\n",
    "カスタム勾配は、Eager ExecutionとGraph Executionの両方の環境で、勾配を上書きする簡単な方法です。 フォワード関数では、\n",
    "入力、出力、または中間結果に関する勾配を定義します。例えば、逆方向パスにおいて勾配のノルムを切り取る簡単な方法は次のとおりです。\n",
    "\n",
    "Custom gradients are an easy way to override gradients in eager and graph\n",
    "execution. Within the forward function, define the gradient with respect to the\n",
    "inputs, outputs, or intermediate results. For example, here's an easy way to clip\n",
    "the norm of the gradients in the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "-OwwsWUAqEhK"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def clip_gradient_by_norm(x, norm):\n",
    "  y = tf.identity(x)\n",
    "  def grad_fn(dresult):\n",
    "    return [tf.clip_by_norm(dresult, norm), None]\n",
    "  return y, grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPLDHkF_qEhN"
   },
   "source": [
    "カスタム勾配は、一連の演算に対して数値的に安定した勾配を提供するために共通的に使用されます。\n",
    "\n",
    "Custom gradients are commonly used to provide a numerically stable gradient for a\n",
    "sequence of operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "24WiLROnqEhO"
   },
   "outputs": [],
   "source": [
    "def log1pexp(x):\n",
    "  return tf.log(1 + tf.exp(x))\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8fq69r9-B-c"
   },
   "outputs": [],
   "source": [
    "# 勾配計算はx = 0のときにうまくいきます。\n",
    "\n",
    "# The gradient computation works fine at x = 0.\n",
    "grad_log1pexp(0.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VFSU0mG-FSp"
   },
   "outputs": [],
   "source": [
    "# しかし、x = 100のときは数値的不安定により失敗します。\n",
    "\n",
    "# However, x = 100 fails because of numerical instability.\n",
    "grad_log1pexp(100.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VcTR34rqEhQ"
   },
   "source": [
    "ここで、 `log1pexp`関数はカスタム勾配を用いて解析的に単純化することができます。\n",
    "以下の実装は、フォワードパスの間に計算された `tf.exp（x）`の値を再利用します - 冗長な計算を排除することでより効率的になります：\n",
    "\n",
    "Here, the `log1pexp` function can be analytically simplified with a custom\n",
    "gradient. The implementation below reuses the value for `tf.exp(x)` that is\n",
    "computed during the forward pass—making it more efficient by eliminating\n",
    "redundant calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "Q7nvfx_-qEhS"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def log1pexp(x):\n",
    "  e = tf.exp(x)\n",
    "  def grad(dy):\n",
    "    return dy * (1 - 1 / (1 + e))\n",
    "  return tf.log(1 + e), grad\n",
    "\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gHPKMfl-Kge"
   },
   "outputs": [],
   "source": [
    "# 上と同様に、勾配計算はx = 0のときにうまくいきます。\n",
    "\n",
    "# As before, the gradient computation works fine at x = 0.\n",
    "grad_log1pexp(0.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u38MOfz3-MDE"
   },
   "outputs": [],
   "source": [
    "# また、勾配計算はx = 100でも機能します。\n",
    "\n",
    "# And the gradient computation also works at x = 100.\n",
    "grad_log1pexp(100.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnZXjfQzqEhV"
   },
   "source": [
    "## パフォーマンス\n",
    "\n",
    "## Performance\n",
    "\n",
    "Eager Executionの間、計算は自動的にGPUにオフロードされます。計算を実行するデバイスを指定したい場合は、\n",
    "`tf.device（ '/ gpu：0'）`ブロック（もしくはCPUを指定するブロック）で囲むことで指定できます。\n",
    "\n",
    "Computation is automatically offloaded to GPUs during eager execution. If you\n",
    "want control over where a computation runs you can enclose it in a\n",
    "`tf.device('/gpu:0')` block (or the CPU equivalent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ac9Y64H-qEhX"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure(x, steps):\n",
    "    \n",
    "  # TensorFlowはGPUを初めて使用するときに初期化します。タイミングから除外します。\n",
    "\n",
    "  # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
    "  tf.matmul(x, x)\n",
    "  start = time.time()\n",
    "  for i in range(steps):\n",
    "    x = tf.matmul(x, x)\n",
    "    \n",
    "  # ｔｆ．ｍａｔｍｕｌは、行列乗算が完了する前に戻ることができます\n",
    "  # （例えば、ＣＵＤＡストリームにオペレーションをエンキューした後に戻すことができます）。\n",
    "  # 以下のx.numpy（）呼び出しは、すべてのキューに入れられた操作が完了したことを確認します\n",
    "  # （そして結果をホストメモリにコピーするため、計算時間は単純なmatmulオペレーションよりも多くのことを含む時間になります。）\n",
    "    \n",
    "  # tf.matmul can return before completing the matrix multiplication\n",
    "  # (e.g., can return after enqueing the operation on a CUDA stream).\n",
    "  # The x.numpy() call below will ensure that all enqueued operations\n",
    "  # have completed (and will also copy the result to host memory,\n",
    "  # so we're including a little more than just the matmul operation\n",
    "  # time).\n",
    "  _ = x.numpy()\n",
    "  end = time.time()\n",
    "  return end - start\n",
    "\n",
    "shape = (1000, 1000)\n",
    "steps = 200\n",
    "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
    "\n",
    "# Run on CPU:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "\n",
    "# Run on GPU, if available:\n",
    "if tfe.num_gpus() > 0:\n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "else:\n",
    "  print(\"GPU: not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLw3IS7UqEhe"
   },
   "source": [
    "`tf.Tensor`オブジェクトはそのオブジェクトに対するオペレーションを実行するために別のデバイスにコピーすることができます。\n",
    "\n",
    "A `tf.Tensor` object can be copied to a different device to execute its\n",
    "operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "ny6LX2BVqEhf"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  x = tf.random_normal([10, 10])\n",
    "\n",
    "  x_gpu0 = x.gpu()\n",
    "  x_cpu = x.cpu()\n",
    "\n",
    "  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
    "  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n",
    "\n",
    "  if tfe.num_gpus() > 1:\n",
    "    x_gpu1 = x.gpu(1)\n",
    "    _ = tf.matmul(x_gpu1, x_gpu1)  # Runs on GPU:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oA_qaII3-p6c"
   },
   "source": [
    "### ベンチマーク\n",
    "\n",
    "### Benchmarks\n",
    "\n",
    "GPUでの\n",
    "[ResNet50]（https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50）\n",
    "の学習のような、計算量の多いモデルの場合は、Eager ExecutionのパフォーマンスはGraph Executionのパフォーマンスに匹敵します。\n",
    "しかし、この2つの環境下のパフォーマンスの違いは計算量の少ないモデルではより大きくなり、小さなたくさんのオペレーションからなるモデルでホットコードパスを最適化するためにやるべきことがあります。\n",
    "\n",
    "For compute-heavy models, such as\n",
    "[ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50)\n",
    "training on a GPU, eager execution performance is comparable to graph execution.\n",
    "But this gap grows larger for models with less computation and there is work to\n",
    "be done for optimizing hot code paths for models with lots of small operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjMTyFIp-sSE"
   },
   "source": [
    "## Graph Executionの実行\n",
    "\n",
    "## Work with graphs\n",
    "\n",
    "Eager Executionは開発とデバッグをより対話的にしますが、\n",
    "TensorFlowのGraph Executionは分散学習、パフォーマンスの最適化、そしてプロダクション環境へのデプロイの観点で利点があります。\n",
    "しかし、Graph Executionのコードの記述方法、標準的なのPythonコードの書き方と異なり、デバッグがより難しく感じるかもしれません。\n",
    "\n",
    "While eager execution makes development and debugging more interactive,\n",
    "TensorFlow graph execution has advantages for distributed training, performance\n",
    "optimizations, and production deployment. However, writing graph code can feel\n",
    "different than writing regular Python code and more difficult to debug.\n",
    "\n",
    "Graph Execution形式のモデルの構築と学習のために、Pythonプログラムは最初に計算グラフを構築し、\n",
    "それからC ++ベースのランタイムで実行するために`Session.run`を呼び出し、グラフを渡します。この機能の特徴は以下のとおりです：\n",
    "\n",
    "For building and training graph-constructed models, the Python program first\n",
    "builds a graph representing the computation, then invokes `Session.run` to send\n",
    "the graph for execution on the C++-based runtime.  This provides:\n",
    "\n",
    "* 静的オートディフを用いた自動微分\n",
    "* プラットフォームに依存しないサーバーへの簡単なデプロイ\n",
    "* グラフベースの最適化（共通的な部分式の削除、定数の畳み込みなど）\n",
    "* コンパイルとカーネルフュージョン\n",
    "* 自動分散とレプリケーション（分散システムへのノード配置）\n",
    "\n",
    "* Automatic differentiation using static autodiff.\n",
    "* Simple deployment to a platform independent server.\n",
    "* Graph-based optimizations (common subexpression elimination, constant-folding, etc.).\n",
    "* Compilation and kernel fusion.\n",
    "* Automatic distribution and replication (placing nodes on the distributed system).\n",
    "\n",
    "Eager Executionのコードは、Graph Executionのコードよりもデプロイが難しいです：モデルから\n",
    "計算グラフを生成するか、またはサーバ上で直接Pythonランタイムからコードを実行する必要があります。\n",
    "\n",
    "Deploying code written for eager execution is more difficult: either generate a\n",
    "graph from the model, or run the Python runtime and code directly on the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hll3ZbE5qEhh"
   },
   "source": [
    "### 互換性のあるコードの記述\n",
    "\n",
    "### Write compatible code\n",
    "\n",
    "Eager Execution環境で記述されたコードは、Eager Executionが有効になっていない新しいPythonセッションで同じコードを実行するだけで\n",
    "同じコードのままGraph Executionで実行することができます。\n",
    "\n",
    "The same code written for eager execution will also build a graph during graph\n",
    "execution. Do this by simply running the same code in a new Python session where\n",
    "eager execution is not enabled.\n",
    "\n",
    "ほとんどのTensorFlowオペレーションはEager Executionで動作しますが、注意すべき点がいくつかあります。\n",
    "\n",
    "Most TensorFlow operations work during eager execution, but there are some things\n",
    "to keep in mind:\n",
    "\n",
    "* 入力処理にはキューの代わりに `tf.data`を使います。この方法はより高速で簡単です。\n",
    "* `tf.keras.layers`や`tf.keras.Model`のような、オブジェクト指向のレイヤAPIを使用します - これらのAPIは変数のための明示的なストレージを持っているためです。\n",
    "* ほとんどのモデルコードは、Eager ExecutionとGraph Executionに同じように機能しますが、例外があります。\n",
    "  （例えば、Pythonによる制御フローで入力に基づいて演算を変更する動的モデルなど）\n",
    "* 一度`tf.enable_eager_execution`によってEager Executionが有効化されると、それを無効化することはできません。\n",
    "  Graph Executionに戻すには、新しいPythonセッションを開始する必要があります。\n",
    "\n",
    "* Use `tf.data` for input processing instead of queues. It's faster and easier.\n",
    "* Use object-oriented layer APIs—like `tf.keras.layers` and\n",
    "  `tf.keras.Model`—since they have explicit storage for variables.\n",
    "* Most model code works the same during eager and graph execution, but there are\n",
    "  exceptions. (For example, dynamic models using Python control flow to change the\n",
    "  computation based on inputs.)\n",
    "* Once eager execution is enabled with `tf.enable_eager_execution`, it\n",
    "  cannot be turned off. Start a new Python session to return to graph execution.\n",
    "\n",
    "以上が、Eager Execution *と* Graph Executionの両方のためのコードを書くためのベストプラクティスです。これによって、\n",
    "Eager Executionによる対話的な実験とデバッガビリティを享受することができ、かつGraph Executionによる分散パフォーマンスの恩恵を受けることができます。\n",
    "\n",
    "It's best to write code for both eager execution *and* graph execution. This\n",
    "gives you eager's interactive experimentation and debuggability with the\n",
    "distributed performance benefits of graph execution.\n",
    "\n",
    "Eager Executionを用いてコードを記述、デバッグ、実験を繰り返したのちにプロダクションへのデプロイのためにモデルパスをimportします。\n",
    "モデル変数を保存およびリストアするには `tf.train.Checkpoint`を使います。これはEager ExecutionとGraph Executionの両環境の互換性を担保します。\n",
    "以下にEager Executionのサンプル集があります：  \n",
    "[tensorflow/contrib/eager/python/examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples)\n",
    "\n",
    "Write, debug, and iterate in eager execution, then import the model graph for\n",
    "production deployment. Use `tf.train.Checkpoint` to save and restore model\n",
    "variables, this allows movement between eager and graph execution environments.\n",
    "See the examples in:\n",
    "[tensorflow/contrib/eager/python/examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPoSUqmL-ts5"
   },
   "source": [
    "### Graph Execution環境でEager Executionを使う\n",
    "\n",
    "### Use eager execution in a graph environment\n",
    "\n",
    "`tfe.py_func`を使ってTensorFlowGraph Execution環境でEager Executionを選択的に可能にすることができます。\n",
    "この機能は、 `tf.enable_eager_execution（）`が呼ばれていないときに使うことができます。\n",
    "\n",
    "Selectively enable eager execution in a TensorFlow graph environment using\n",
    "`tfe.py_func`. This is used when `tf.enable_eager_execution()` has *not*\n",
    "been called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "py"
     ],
     "id": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "Lks-3LB0qEhi"
   },
   "outputs": [],
   "source": [
    "def my_py_func(x):\n",
    "  x = tf.matmul(x, x)  # You can use tf ops\n",
    "  print(x)  # but it's eager!\n",
    "  return x\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  x = tf.placeholder(dtype=tf.float32)\n",
    "  # Call eager function in graph!\n",
    "  pf = tfe.py_func(my_py_func, [x], tf.float32)\n",
    "\n",
    "  sess.run(pf, feed_dict={x: [[2.0]]})  # [[4.0]]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Eager.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
