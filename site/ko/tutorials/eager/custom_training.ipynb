{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rmpybwysXGV"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "m8y3rGtQsYP2"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrXv0rU9sIma"
   },
   "source": [
    "# 사용자 정의 학습: 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7S0BwJ_8sLu7"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/eager/custom_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2o3TTG4TFpt"
   },
   "source": [
    "이전 튜토리얼에서 우리는 머신러닝을 위한 기초 빌딩 블록인 자동미분(automatic differentiation)을 위한 텐서플로우 API들을 알아보았습니다. 이번 튜토리얼에서는 이전 튜토리얼에서 소개되었던 초기 타입의 텐서플로우를 사용하여 간단한 머신러닝을 구축해보겠습니다. \n",
    "\n",
    "텐서플로우는 상용구를 줄이기 위해 유용한 추상화를 제공하는 고수준 신경망 API인 (`tf.keras`)를 포함하고 있습니다. 신경망에 관련하여 일을 하고 있는 사람들에게는 이러한 고수준의 API들을 강하게 추천합니다. 그러나 이번 짧은 튜토리얼에서는 탄탄한 기초를 기르기 위한 신경망 학습을 다루겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LXMVuV0VhDr"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJ64L90aVir3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82108\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMAWbDJFVmMk"
   },
   "source": [
    "## 변수\n",
    "\n",
    "텐서플로우 안에서 텐서(Tensor)는 상태가 없고, 변경이 불가능한(immutable stateless) 객체입니다. 그러나 머신러닝은 상태가 변경될 필요가 있습니다(stateful). 예를 들어, 모델 학습에서 예측을 계산하기 위한 동일한 코드는 시간이 지남에 따라 다른 양상(희망적으로, 더 낮은 손실로 가는 방향으로)을 보여야 합니다. 이 계산 과정을 통해 변화되어야 하는 상태를 표현하기 위해 상태가 변경 가능한 파이썬 언어에 의존한 선택이 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkJwtLS_Jbn8"
   },
   "outputs": [],
   "source": [
    "# 파이썬 state 사용\n",
    "x = tf.zeros([10, 10])\n",
    "x += 2  # 이것은 x = x + 2 같으며, 초기값 x를 변경하지 않습니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfneTXy7JcUz"
   },
   "source": [
    "그러나 텐서플로우는 상태가 변경 가능한 연산자들이 내장되어 있으며, 이 연산자들은 상태를 표현하기 위한 저수준 파이썬 표현보다 사용하기가 더 좋습니다. 예를 들어, 모델에서 가중치를 나타내기 위해서 텐서플로우 변수를 사용하는것이 편하고 효율적입니다.  \n",
    "\n",
    "텐서플로우 변수는 값을 저장하고 텐서플로우 계산에 사용될 때 묵시적으로 저장된 값을 읽어오는 객체입니다. `tf.assign_sub`, `tf.scatter_update` 등은 텐서플로우 변수에 저장되있는 값을 조작하는 연산자들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itxmrMil6DQi"
   },
   "outputs": [],
   "source": [
    "v = tf.Variable(1.0)\n",
    "assert v.numpy() == 1.0\n",
    "\n",
    "# 값 재배열\n",
    "v.assign(3.0)\n",
    "assert v.numpy() == 3.0\n",
    "\n",
    "# 텐서플로우 연산자 내에서 `v` 사용 \n",
    "v.assign(tf.square(v))\n",
    "assert v.numpy() == 9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-paSaeq1JzwC"
   },
   "source": [
    "변수들을 사용한 계산은 그래디언트가 계산될 때 자동적으로 추적됩니다. 임베딩(embedding)을 나타내는 변수의 경우 초기값으로부터 드물게 업데이트됩니다. 이는 계산과 메모리에 있어 더욱 효율적입니다. \n",
    "\n",
    "또한 변수를 사용하는 것은 코드를 읽는 과정에서 변경 가능한 상태(state mutable)의 조각을 빠르게 인식하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMiFcDzE7Qu3"
   },
   "source": [
    "## 예: 선형모델 피팅\n",
    "\n",
    "몇가지 개념들을 설명해보겠습니다. 우리는 지금까지 간단한 모델을 구축하고 학습시키기 위해 ---`Tensor`, `GradientTape`, `Variable` --- 등을 사용하였습니다. 이것은 전형적으로 다음의 과정을 포함합니다.\n",
    "\n",
    "1. 모델 정의\n",
    "2. 손실함수 정의\n",
    "3. 훈련 데이터 가져오기\n",
    "4. 훈련 데이터를 통한 실행, 데이터에 최적화하기 위한 \"옵티마이저(optimizer)\" 사용한 변수 조정\n",
    "\n",
    "이번 튜토리얼에서는 선형모델의 간단한 예제를 살펴보겠습니다. `f(x) = x * W + b`, 위 모델은 `W` 와 `b` 두 변수를 가지고 있는 선형모델이며, 잘 학습된 모델이 `W = 3.0` and `b = 2.0`의 값을 갖도록 데이터를 합성할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFzH64Jn9PIm"
   },
   "source": [
    "### 모델 정의\n",
    "\n",
    "변수들과 계산을 요약하기 위한 간단한 클래스를 정의해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WRu7Pze7wk8"
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "  def __init__(self):\n",
    "    # 변수 초기화 (5.0, 0.0)\n",
    "    # 실제로는 임의의 값으로 초기화 되어야합니다.\n",
    "    self.W = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    return self.W * x + self.b\n",
    "  \n",
    "model = Model()\n",
    "\n",
    "assert model(3.0).numpy() == 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xa6j_yXa-j79"
   },
   "source": [
    "### 손실 함수 정의\n",
    "\n",
    "손실 함수는 주어진 입력에 대한 모델의 출력이 원하는 출력과 얼마나 잘 일치하는지를 측정합니다. L2 규제항(regularization)을 적용한 손실 함수를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0ysUFGY924U"
   },
   "outputs": [],
   "source": [
    "def loss(predicted_y, desired_y):\n",
    "  return tf.reduce_mean(tf.square(predicted_y - desired_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qutT_fkl_CBc"
   },
   "source": [
    "### 훈련 데이터 얻기\n",
    "\n",
    "약간의 잡음과 훈련 데이터를 합칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxPTb-kt_N5m"
   },
   "outputs": [],
   "source": [
    "TRUE_W = 3.0\n",
    "TRUE_b = 2.0\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "inputs  = tf.random_normal(shape=[NUM_EXAMPLES])\n",
    "noise   = tf.random_normal(shape=[NUM_EXAMPLES])\n",
    "outputs = inputs * TRUE_W + TRUE_b + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-50nq-wPBsAW"
   },
   "source": [
    "모델을 훈련시키기 전에, 모델의 현재 상태를 시각화합시다. 모델의 예측을 빨간색으로, 훈련데이터를 파란색으로 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eb83LtrB4nt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: \n",
      "9.401943\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(inputs, outputs, c='b')\n",
    "plt.scatter(inputs, model(inputs), c='r')\n",
    "plt.show()\n",
    "\n",
    "print('Current loss: '),\n",
    "print(loss(model(inputs), outputs).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSDP-yeq_4jE"
   },
   "source": [
    "### 훈련 루프 정의\n",
    "\n",
    "현재 우리는 네트워크와 훈련 데이터를 가지고 있습니다. 모델의 변수(`W` 와 `b`)를 업데이트하기 위해 훈련 데이터를 사용하여 훈련시킵니다. 그리고 [경사하강(gradient descent)](https://en.wikipedia.org/wiki/Gradient_descent)를 사용하여 손실을 감소시킵니다. 경사하강에는 여러가지 방법이 있으며, `tf.train.Optimizer` 에 구현되어있습니다. 이러한 구현을 사용하는것을 강력히 추천드립니다. 그러나 이번 튜토리얼에서는 기본적인 방법을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBIACgdnA55X"
   },
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, learning_rate):\n",
    "  with tf.GradientTape() as t:\n",
    "    current_loss = loss(model(inputs), outputs)\n",
    "  dW, db = t.gradient(current_loss, [model.W, model.b])\n",
    "  model.W.assign_sub(learning_rate * dW)\n",
    "  model.b.assign_sub(learning_rate * db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwWPaJryD2aN"
   },
   "source": [
    "마지막으로, 훈련 데이터를 반복적으로 실행하고, `W` 와 `b`의 변화과정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdfkR223D9dW"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "# 도식화를 위해 W값과 b값들의 변화를 저장합니다.\n",
    "Ws, bs = [], []\n",
    "epochs = range(10)\n",
    "for epoch in epochs:\n",
    "  Ws.append(model.W.numpy())\n",
    "  bs.append(model.b.numpy())\n",
    "  current_loss = loss(model(inputs), outputs)\n",
    "\n",
    "  train(model, inputs, outputs, learning_rate=0.1)\n",
    "  print('Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f' %\n",
    "        (epoch, Ws[-1], bs[-1], current_loss))\n",
    "\n",
    "# Let's plot it all\n",
    "plt.plot(epochs, Ws, 'r',\n",
    "         epochs, bs, 'b')\n",
    "plt.plot([TRUE_W] * len(epochs), 'r--',\n",
    "         [TRUE_b] * len(epochs), 'b--')\n",
    "plt.legend(['W', 'b', 'true W', 'true_b'])\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPnIVuaSJwWz"
   },
   "source": [
    "## 다음 단계\n",
    "\n",
    "이번 튜토리얼에서는 `Variable`를 다루었으며, 지금까지 논의된 초기 타입의 텐서플로우를 사용하여 간단한 선형모델을 구축하고 훈련시켰습니다.\n",
    "\n",
    "이론적으로, 이것은 머신러닝 연구에 텐서플로우를 사용하는데 필요한 대부분입니다. 실제로, 신경망에 있어 `tf.keras`와 고수준 API들은 고수준 빌딩 블록(\"layer\"로 불리는)을 제공하고, 저장 및 복원을 위한 유틸리티, 손실함수 모음, 최적화 전략 모음 등을 제공하기 때문에 더욱 편리합니다. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Custom training: basics",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
